---
layout: doc
title:  "사용법"
---

## Mediclassics Analyzer

[한의학고전DB](https://mediclassics.kr/)의 데이터를 이용하여 사용자가 입력한 용어와 관련이 높은 용어를 출력해 줍니다.

<br>

### 검색 용어 및 조건 입력 <small>Search Term Setting</small>

분석에 사용될 검색어를 입력합니다. 정해진 특수문자 외에는 모두 한자로 입력해야 오류 없이 검색 결과를 얻을 수 있습니다.

주검색어(Main Term)

* 검색에서 중심이 될 검색어를 의미합니다. 시스템은 가장 먼저 이 검색어를 검색해 둡니다.
* 1가지 용어만 입력 받지만, `|` 기호로 여러 단어를 붙여 `or` 검색의 효과를 볼 수 있습니다.
* 예를 들어 `咳嗽|咳喘|喘咳`라고 입력하면 대상 텍스트에서 "咳嗽", "咳喘", "喘咳"를 모두 검색합니다.

보조검색어(Included Term, Excluded Term)

* 주검색어를 포함하면서, 함께 포함되어야 하거나 포함되지 말아야 할 추가 검색어를 설정할 수 있습니다.
* '포함어(Included Term)'는 주검색어와 함께 포함되어야 할 검색어를 의미합니다.
* '제외어(Excluded Term)'는 주검색어에도 불구하고 제외되어야 할 검색어를 의미합니다.
* 양자는 `|` 기호를 통해 `or` 검색의 효과를, 공백(띄어쓰기)를 통해 `and` 검색의 효과를 얻을 수 있습니다.
* 예를 들어 포함어를 `痰|唾 夜`라고 하고, 제외어를 `上氣 咳逆`라고 하면, 주 검색어가 포함된 텍스트에서 痰나 唾가 반드시 포함되고, 夜 역시 반드시 포함되지만, 上氣와 咳逆는 모두 포함되지 않는 경우를 한 번 더 도출하게 됩니다.
* 포함어와 제외어를 지나치게 자세히 설정하면 조건에 부하하는 텍스트의 양이 적어져 최종 결과를 신뢰할 수 없을 수 있습니다.

N그램 범위(Ngram Range)

* 토큰의 글자 크기를 제한합니다.
* 현재는 최소값(Min)을 2, 최대값(Max)를 8로 제한되어 있습니다. 가장 작은 토큰의 글자 수가 2, 가장 큰 토큰의 글자 수가 8로 지정됩니다.
* 단 'DictSegmenter'를 선택했을 때, 용어집에 8보다 긴 글자가 있다면 토큰으로 인정합니다.

윈도우 크기(Half Window Size)

* 주검색어를 중심으로 얼마나 많은 단어들을 포함시킬 것인지를 결정합니다.
* 예를 들어 16이라고 한다면, 주검색어 좌우의 16자를 분석 대상에 포함시킵니다.
* 대상 텍스트를 "전체 텍스트"로 했을 때만 의미를 가집니다.

Top n

* 분석 결과를 몇 가지 가져올 지 선택합니다.

<br>

### 분석 방법 설정 <small>Analysis Method Setting</small>

대상 코퍼스(Target Corpus) : 검색어를 적용할 텍스트를 선택합니다.

* <kbd>전체 텍스트</kbd>는 서버에 저장되어 있는 모든 한의학 고문헌 텍스트입니다. 양이 많지만 치료와 관련되지 않은 내용들도 다수 섞여 있습니다.
* <kbd>치료 텍스트</kbd>는 "전체 텍스트"에서 치료와 관련된 텍스트만을 추출해 놓은 별도의 텍스트입니다. 양이 적지만 치료와 관련된 텍스트의 밀도가 높습니다.

토큰 추출 모델

* 토큰은 분석에 적용될 텍스트의 최소 단위입니다. 한문의 경우 글자 하나를 토큰으로 볼 수도 있고 몇 가지 글자를 합쳐 하나의 토큰으로 볼 수도 있습니다.
* <kbd>DictSegmenter</kbd>, <kbd>ScoreSegmenter</kbd>, <kbd>NgramTokenizer</kbd>의 3가지 방법이 있습니다. 각각의 내용은 아래 Mediclassics Segmenter의 [파라미터 설정](#파라미터-설정) 부분을 참고해 주시기 바랍니다.

<br>

### 분석 실행

<kbd>ANALYZE</kbd> 버튼을 누르면 분석을 수행하여 아래 영역에 그 결과가 출력됩니다.

<br>

***

<br>

## Mediclassics Segmenter

사용자가 입력한 원문을 적절한 용어로 구분해 줍니다. 이렇게 구분된 용어를 토큰(Token), 이러한 과정을 토크나이제이션(Tokenization) 혹은 세그멘테이션(Segmentation)이라고 지칭합니다. 이렇게 나누어진 토큰은 텍스트 분석에서 최소 단위로 사용됩니다.

<br>

### 원문의 입력 <small>Target Text Setting</small>

'Target Text' 아래 있는 텍스트 영역에 세그멘테이션 하고자 하는 텍스트를 입력합니다.

<br>

### 세그멘테이션 방법 설정 <small>Method Setting</small>

파라미터를 선택하여 결과값을 조정할 수 있습니다.

Segment Markup : 토큰을 좌우에서 표시할 기호를 입력합니다.

* 기본값은 왼쪽 '〔', 오른쪽 '〕'으로 되어 있습니다.

Segment Model : 세그멘테이션을 수행할 모델을 선택합니다.

* <kbd>DictSegmenter</kbd> : 용어사전을 기반으로 세그멘테이션을 수행합니다. 정확하다는 장점이 있지만, 용어사전에 없는 토큰은 생성되지 않습니다.
* <kbd>ScoreSegmenter</kbd> : 글자 사이에 점수를 계산하여 세그멘테이션을 수행합니다. 용어사전과 같은 추가 데이터가 필요하지 않다는 장점이 있지만, 빈도가 높은 글자의 조합이 우선적으로 추출되므로 오류가 있을 수 있습니다.
* <kbd>NgramTokenizer</kbd> : 최소 2자에서 최대 8자 사이의 글자 조합을 모두 추출해 줍니다.

<br>

### 분석 실행

<kbd>SEGMENT</kbd> 버튼을 누르면 분석을 수행하여 아래 텍스트 영역에 그 결과가 출력됩니다.
