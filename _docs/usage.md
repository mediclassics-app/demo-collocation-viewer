---
layout: doc
title:  "사용법"
---

## 개요


분석 조건 및 검색어를 설정 한 뒤에 분석(ANALYZE) 버튼을 누른다.


### 분석 조건

대상 텍스트 : 검색어를 적용할 대상 텍스트를 선택합니다.
* "전체 텍스트"는 서버가 저장하고 있는 모든 한의학 고문헌 텍스트입니다. 양이 많지만 치료와 관련되지 않은 내용들도 다수 섞여 있습니다.
* "치료 텍스트"는 "전체 텍스트"에서 치료와 관련된 텍스트만을 추출해 놓은 별도의 텍스트입니다. 양이 적지만 치료와 관련된 텍스트의 밀도가 높습니다.

토큰 추출
* 토큰은 분석에 적용될 텍스트의 최소 단위입니다. 한문의 경우 글자 하나를 토큰으로 볼 수도 있고 몇가지 글자를 합쳐 하나의 토큰으로 볼 수도 있습니다.
* "DictSegmenter"는 서버에 이미 저장된 용어집을 기준으로 텍스트를 나누어 토큰을 추출합니다. 예시는 아래와 같습니다.
  - 대상 텍스트: "東垣曰, 內傷脾胃, 致中氣虛少, 宜補中益氣湯, 益胃升陽湯"
  - 용어집 : ['東垣', '內傷', '脾胃', '內傷脾胃', '中氣', '補中', '補中益氣湯', '益胃升陽湯']
  - ngram range: (2,8)
  - 토큰 : ["東垣", "內傷脾胃", "中氣", "補中益氣湯", "益胃升陽湯"]
* "ScoreSegmenter"는 텍스트 전체의 용어 빈도를 통해 단어일 가능성을 점수로 산정한 다음 이를 기준으로 텍스트를 나누어 토큰을 추출하는 방법입니다.
  - 대상 텍스트: "東垣曰, 內傷脾胃, 致中氣虛少, 宜補中益氣湯, 益胃升陽湯"
  - 용어일 점수 :
  - ngram range: (2,8)
  - 토큰 : ""
* "NgramTokenizer"는 복잡한 계산 없이 글자 수를 기준으로 토큰을 추출한 결과입니다.
  - 대상 텍스트: "東垣曰, 內傷脾胃, 致中氣虛少, 宜補中益氣湯, 益胃升陽湯"
  - ngram range: (2,8)
  - 토큰 : ""



### 검색어

본 검색기는 main text와 sub text와의 비교를 통해 점수를 산정합니다.
* 여기서 main text는 위에서 선택한 치료 텍스트 혹은 전체 텍스트가 됩니다.
* 검색어는 main text에서 해당 검색어를 만족하는 텍스트를 추출하여 sub text로 만들기 위한 기준입니다.

주검색어(MAIN)
* 검색에서 중심이 될 검색어를 의미합니다. 시스템은 가장 먼저 이 검색어를 검색해 둡니다.
* MAIN 검색어는 1가지만 가능하지만, "|" 기호로 여러 단어를 붙여 `or` 검색의 효과를 볼 수 있습니다.
* `咳嗽|咳喘|喘咳`라고 입력하면 대상 텍스트에서 "咳嗽", "咳喘", "喘咳" 가운데 한 가지라도 포함되어 있다면 subtext로 분류합니다.

보조검색어(AND, NOT)
* MAIN 검색어로 첫번째 sub text를 구성하고 난 뒤에
* AND 검색어가 들어 있지 않은 text와 NOT 검색어가 포함된 텍스트를 버리게 됩니다.
* 양자는 "|"기호를 통해 `or` 검색의 효과를, 공백(띄어쓰기)를 통해 `and` 검색의 효과를 얻을 수 있습니다.
  - 예를 들어 AND : `痰|唾 夜`라고 하고, NOT : `上氣 咳逆`라고 하면 sub text에는 痰나 唾가 반드시 포함되고, 夜 역시 반드시 포함되지만, 上氣와 咳逆는 모두 포함되지 않는 경우를 도출하게 됩니다.

Half Window Size
* 주검색어를 중심으로 얼마나 많은 단어들을 포함시킬 것인지를 결정합니다. 대상 텍스트를 "전체 텍스트"로 했을 때만 의미를 가집니다.
  - 예를 들어 16이라고 한다면, 주검색어 좌우의 16자를 sub text로 포함시킵니다.

Ngram Range
* 토큰의 글자 크기를 제한합니다.
  - 예를 들어 (2,8)이라면, 가장 작은 토큰의 글자 수가 2, 가장 큰 토큰의 글자 수가 8로 지정됩니다.
* 단 'DictSegmenter'를 선택했을 때, 용어집에 8보다 긴 글자가 있다면 토큰으로 인정합니다.
* 또한 가장 작은 토큰의 글자 킥을 1로 하면 정상적인 결과가 출력되지 않을 수 있습니다.


top n
* 분석 결과를 몇가지 가져올 지 선택합니다.
